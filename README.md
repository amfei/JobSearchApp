ğŸ§­ AI-Assisted Job Search Ranker
ğŸš€ Overview

JobSearchApp is an intelligent job-matching tool built with Streamlit, LangGraph-style pipelines, and semantic search to help users automatically find the most relevant job postings based on their CV.

It scrapes job data (from LinkedIn or other boards), extracts job information, ranks postings using both keyword (BM25) and semantic similarity (Sentence-Transformers), and optionally sends a daily summary email with top matches.

ğŸ§° Features
Feature Description
ğŸ“„ CV Parsing Extracts text automatically from uploaded or pre-defined PDF CVs
ğŸŒ LinkedIn Scraper Uses requests + BeautifulSoup + (optional) Selenium / undetected_chromedriver
ğŸ§  Hybrid Ranking Combines BM25 keyword relevance with Sentence-Transformer embeddings
ğŸ’¾ Vector Database Stores job postings in ChromaDB for re-ranking and historical searches
ğŸ“§ Email Report Sends your top job matches directly to your inbox using Gmail App Password
ğŸ§© Streamlit UI Interactive sidebar controls and job explorer dashboard
ğŸ” Secure Secrets Uses .env locally and Streamlit Secrets in production
ğŸ—‚ï¸ Project Structure
JobSearchApp_final/
â”œâ”€â”€ app.py # Streamlit main app
â”œâ”€â”€ pipeline/
â”‚ â”œâ”€â”€ config.py # Environment + runtime settings
â”‚ â”œâ”€â”€ cv_reader.py # PDF CV text extraction
â”‚ â”œâ”€â”€ email_utils.py # Gmail SMTP email sender
â”‚ â”œâ”€â”€ ranker.py # BM25 + embeddings hybrid ranking
â”‚ â”œâ”€â”€ vectordb.py # ChromaDB vector store
â”‚ â””â”€â”€ sources/
â”‚ â”œâ”€â”€ **init**.py
â”‚ â””â”€â”€ boards.py # LinkedIn scraper (requests + Selenium)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

âš™ï¸ Installation (Local / VSCode)

Clone the repo

git clone https://github.com/<your_username>/JobSearchApp_final.git
cd JobSearchApp_final

Create & activate virtual environment

python -m venv .venv
source .venv/bin/activate # macOS/Linux

# .venv\Scripts\activate # Windows

Install dependencies

pip install -U pip
pip install -r requirements.txt

Set up .env

SENDER_EMAIL=your_gmail@gmail.com
GMAIL_APP_PASSWORD=your_16_char_app_password
RECIPIENT_EMAIL=you@outlook.com
CV_PDF_PATH=./CV.pdf
EMBEDDING_MODEL=sentence-transformers/all-mpnet-base-v2
USE_SELENIUM=true
SEND_EMAIL=true
SCRAPE_ALWAYS=true
CHROMA_DIR=.chroma

Run the app

streamlit run app.py

â˜ï¸ Deployment on Streamlit Cloud

Push your repo to GitHub.

Go to streamlit.io/cloud
â†’ Deploy New App â†’ select your repo.

Add your secrets under Settings â†’ Secrets in TOML format:

SENDER_EMAIL = "your_gmail@gmail.com"
GMAIL_APP_PASSWORD = "your_16_char_app_password"
RECIPIENT_EMAIL = "you@outlook.com"
CV_PDF_PATH = "./CV.pdf"
EMBEDDING_MODEL = "sentence-transformers/all-mpnet-base-v2"
USE_SELENIUM = "false"
SEND_EMAIL = "false"
SCRAPE_ALWAYS = "true"
CHROMA_DIR = ".chroma"

Click Deploy.
Note: Selenium will not run on Streamlit Cloud (set USE_SELENIUM=false).

ğŸ“§ Gmail App Password Setup

If you get an authentication error (SMTPAuthenticationError 535):

Enable 2-Step Verification in your Google account.

Create an App Password for "Mail" â†’ â€œOther (Streamlit)â€ â†’ copy the 16-character code.

Paste that code as GMAIL_APP_PASSWORD in .env or Secrets.

Official Google guide â†’

ğŸ§  Technical Details
Module Key Libraries
CV extraction pdfplumber
Job scraping requests, BeautifulSoup, selenium, webdriver-manager, undetected-chromedriver
Ranking rank_bm25, sentence-transformers, chromadb
UI streamlit
Email smtplib, email.mime
Workflow Designed modularly for LangGraph / DAG-style orchestration
ğŸ”’ Security Notes

Never commit your .env file â€” itâ€™s in .gitignore.

Use Streamlit Secrets for deployment credentials.

Avoid running Selenium scraping on Streamlit Cloud (it needs a Chrome driver).

Use responsibly â€” scraping LinkedIn HTML is unofficial and may violate their ToS.

ğŸ§© Example Workflow

Upload your CV (PDF)

Choose job titles & locations

Click Fetch Jobs (scrapes from LinkedIn)

Click Rank Matches (relevance to your CV)

Click Email Results to send a summary

ğŸ§­ Future Enhancements

Add progress bar with ETA during scraping

Integrate multiple job sources (Indeed, Glassdoor, Greenhouse)

Add OpenAI summarizer for each job description

Enable scheduling (daily auto-email jobs)

Build REST API endpoint for automation

ğŸ‘¨â€ğŸ’» Author

Amir Feizi, PhD
AI & Data Science Engineer | Finzzor AI Founder
ğŸ“ Montreal, Canada
